# Towards Functional and Efficiency Dual Guidance for LLM-based Code Optimization

<img width="2855" height="1798" alt="all" src="https://github.com/user-attachments/assets/bf04792b-cebc-4ac6-943e-5586a5abc83a" />





## Introduction


Code developed by programmers often suffers from inefficiencies,
and extensive research efforts have been devoted to automated
refactoring techniques for code optimization. Early optimization
techniques primarily employed rule-based strategies, which are
costly and limited to resolving specific inefficiencies. Recent studies
have approached code optimization as a sequence generation task,
leveraging deep learning technologies such as large language models (LLMs). While these approaches have demonstrated advanced
performance, they do not consider code semantic well and thus suffer from correctness and efficacy issues. To alleviate the issues, we
propose GBLLM, a guidance-based LLMs framework that synergistically integrates LLMs with functional and efficient dual guidance.
GBLLM comprises three critical components: 

1) Slow-to-Fast EffiCFG Knowledge Base is retrieval-based that links the slow code
with the Effi-CFG for its corresponding fast code, where Effi-CFG
is a succinct representation to encapsulate algorithmic information
of code;

2) Code Description Based Functional Guidance generates
descriptive representations of inefficient code, which, together with
input/output functional descriptions, guide LLMs to generate faster
code with identical functionality;

3) Efficient Guidance Using Fast
Effi-CFG utilizes fast Effi-CFG retrieved from the knowledge base
to direct LLMs in refactoring algorithmic structures, resulting in
improved efficiency.

The evaluation on the widely used benchmark
PIE as well as on the PPIE dataset we constructed demonstrates
that GBLLM achieves state-of-the-art performance, highlighting
the effectiveness of combining a dual-guidance strategy with LLMs
to improve code optimization efficiency.



## Dependency

Python == 3.13.5

Linux

Run the following command in the root directory of this repo:

```sh
pip install -r requirements.txt
```




## Replication Guide

To reproduce the results presented in the paper, please follow the instructions outlined below. The results for each section are provided at the end of their respective chapters, where you can also find them to skip some of the following steps.

First, install the required dependencies as described above.


This section provides instructions for reproducing the experimental results presented in the paper, with the following research questions (RQ):

 - `RQ1`: How effective is GBLLM in enhancing code efficiency?

 - `RQ2`: What are the fine-grained performance characteristics of code generated by GBLLM at various optimization levels?

 - `RQ3`: How do individual components of GBLLM contribute to overall performance?




### Comparison of GBLLM and Baselines (RQ1)


Baselines: The source code of other baseline methods is in the `baselines/` folder. Detailed instructions on how to use them can be found in the `README.md` file within the `baselines/` folder.


GBLLM: Steps to reproduce the results. To reproduce the experimental results, follow these steps:
1) Data Access: Download the necessary datasets for using GBLLM, specifically the Slow-to-Fast Effi-CFG Knowledge Base and PIE_processed_data.
2) Running GBLLM and Obtaining Results: Use GBLLM to generate code data on four different LLMs (Large Language Models). The generated results can be found in the Results Generated by GBLLM section.
3) Generate Code Evaluation Results Using Metrics (PPT and SP): Analyze the code generated by GBLLM to obtain the OPT (Optimization) and SP (Speed) metrics.



#### 1. Data Access

We use the following scripts to process the data, which are described as follows:

 - `API__code_sanitization.py`: This script is used for dataset and code preprocessing, which is performed at two levels: simple sanitization and complex sanitization. The dataset undergoes complex sanitization, while GBLLM uses simple sanitization.

 - `API__Remove_Inline_Breaks.py`: This script addresses line-breaking issues caused by the Abstract Syntax Tree (AST) sanitization, which results in excessively long lines of code.

 - `API__unify_variable_name_function.py`: This script standardizes the variable and function names across the code.


The download links for the datasets are provided below:

 - For `CodeLLaMa`, `Gemini`, and `ChatGPT`: Download `*Datasets*`

 - For `GPT-4`: Download `*GPT4 Dataset*`



|                | **Language** | **Datasets**   | **GPT4 Dataset**             | **Slow-to-Fast Effi-CFG Knowledge Base**         |
|----------------|--------------|----------------|------------------------------|--------------------------------------------------|
| **PIE-C++**    | C++          | [PIE_Cpp.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PIE)    | [PIE_Cpp_GPT4_dataset.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PIE)     | [Cpp__Slow_to_Fast_Effi_CFG_Knowledge_Base.csv](https://drive.google.com/file/d/1ABxqsy-PrBl7ZeMEKyAq8JtAuyRve3l2/view?usp=sharing)    |
| **PIE-Python** | Python       | [PIE_Python.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PIE) | [PIE_Python_GPT4_dataset.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PIE)  | [Python__Slow_to_Fast_Effi_CFG_Knowledge_Base.csv](https://drive.google.com/file/d/1qAoQFykxLnCOq1MjGN4aqJW1o2RAj5Kc/view?usp=sharing) |
| **PPIE**       | Python       | [PPIE.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PPIE)       | [PPIE_Python_GPT4_dataset.csv](https://github.com/CodeGeneration2/GBLLM/tree/main/PPIE) | [Python__Slow_to_Fast_Effi_CFG_Knowledge_Base.csv](https://drive.google.com/file/d/1qAoQFykxLnCOq1MjGN4aqJW1o2RAj5Kc/view?usp=sharing) |




#### 2. Running GBLLM and Obtaining Results

In this section, you will generate results using GBLLM.

Our code relies on the service of OpenAI (for ChatGPT, GPT-4), Google (for Gemini), and DeepInfra (for CodeLLaMa), so you need first obtain their API keys. After obtaining the API keys, execute the following command to generate code data from GBLLM across four different LLMs.

```bash
cd GBLLM 
bash Generate_Code.sh
```

Description of the Python scripts used in `Generate_Code.sh`:

 - `API__LLMs.py`:  A wrapper for generating code using LLMs, which includes four different LLMs.

 - `Large_model_API_generation.py`: A Python script for generating code functionality descriptions and optimized fast code using GBLLM.


Results Generated by GBLLM: The following are the results generated by GBLLM on four different LLMs. These include both the generated descriptions of slow code functionalities and the optimized fast code. For each case, GBLLM performs a single round of generation, where the functionality description consists of one entry, while five versions of the fast code are generated.


|                | **Language** | **GBLLM Generated Code (Includes CodeLlama, Gemini, GPT-3.5 and GPT4)** |
|:--------------:|:------------:|:-----------------------------------------------------------------------:|
| **PIE-C++**    | C++          | [PIE C++ Generated Code](https://drive.google.com/drive/folders/10FCicOLQCJNIuSQT5zKDkkzz2_KIVsyq?usp=sharing)                                                  |
| **PIE-Python** | Python       | [PIE Python Generated Code](https://drive.google.com/drive/folders/1_3rJ3uUfrpHjIfuNbES9o_TRIdxgZ_cd?usp=sharing)                                               |
| **PPIE**       | Python       | [PPIE Python Generated Code](https://drive.google.com/drive/folders/1YIG93Uhcb8AFTcpDEomSQtiktsTig3xy?usp=sharing)                                              |



#### 3. Generate Code Evaluation Results Using Metrics (PPT and SP)

You can use the following script to calculate and report the OPT and SP metrics for the files generated by GBLLM:

```bash
cd GBLLM 
bash Statistical_Generation_Code_Data_RQ1.sh
```

Description of the Python script used in `Statistical_Generation_Code_Data_RQ1.sh`:

`Statistical_Generation_Code_Data.py`:  A script for calculating and reporting the OPT and SP metrics for the files generated by GBLLM.





### Fine-Grained Analysis of GBLLM (RQ2)

Using the code data generated in RQ1, you can use the following script to generate the bar charts for RQ2, as presented in the paper:

```bash
cd Drafting/Histogram
bash Statistically_Generated_Code_Versus_Humans_RQ2.sh
```

Description of the Python scripts used in `Statistically_Generated_Code_Versus_Humans_RQ2.sh`:

 - `Statistically_Generated_Code_Versus_Humans_RQ2.py`:  Extracts data needed for generating the bar charts.
 - `Drawing_Bar_Charts_Versus_Humans.py`: Generates the bar charts.


To generate the violin plot for RQ2 in the paper, use the following script:

```bash
cd Drafting/Violin_Figure
bash Drawing_the_violin_RQ2.sh
```

Description of the Python scripts used in `Drawing_the_violin_RQ2.sh`:

 - `python Standard_Line_Dictionary.py`: Retrieves human reference data required for generating the bar chart.
 - `python Gen_Full_Model_Data_Dictionary.py`: Retrieves GBLLM-generated Gen 1, 3, 5 data for the bar chart.
 - `python Top_Full_Model_Data_Dictionary.py`: Retrieves GBLLM-generated Top 1, 3, 5 data for the bar chart.
 - `python Drawing_the_violin.py`: Generates the violin plot.





### Ablation Study of GBLLM (RQ3)


Please use the following script to generate the code for the ablation study:

```bash
cd GBLLM 
bash Ablation_RQ3.sh
```



You can use the following script to calculate and report the OPT and SP metrics for the data generated by GBLLM in the ablation study:

```bash
cd GBLLM 
bash Ablation_Statistical_Code_RQ3.sh
```


Ablation Results of GBLLM: The following are the ablation results of GBLLM on ChatGPT, which include both the generated descriptions of slow code functionalities and the optimized fast code.

Ablation Results: [GBLLM__Ablation.csv](https://drive.google.com/drive/folders/1tFGk_zWC1nGX2UY5YblA3JEkztUYCEcW?usp=sharing)


